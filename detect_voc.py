from ultralytics import YOLO
import cv2
import os
import time

# VOCç±»åˆ«ä¸­æ–‡åç§°
VOC_CLASSES_CN = [
    "é£æœº", "è‡ªè¡Œè½¦", "é¸Ÿ", "èˆ¹", "ç“¶å­", "å…¬äº¤è½¦", "æ±½è½¦", "çŒ«", 
    "æ¤…å­", "ç‰›", "é¤æ¡Œ", "ç‹—", "é©¬", "æ‘©æ‰˜è½¦", "äºº",
    "ç›†æ ½", "ç¾Š", "æ²™å‘", "ç«è½¦", "ç”µè§†"
]

print("ğŸ“¦ åŠ è½½YOLOv8æ¨¡å‹...")

# æŸ¥æ‰¾è®­ç»ƒæ¨¡å‹
model_paths = [
    "runs/detect/train/weights/best.pt",  # æ ‡å‡†ä½ç½®
    "runs/detect/train/weights/last.pt",  # æœ€åä¸€æ¬¡ä¿å­˜çš„æ¨¡å‹
    "yolov8n.pt"                          # é¢„è®­ç»ƒæ¨¡å‹(å¤‡ç”¨)
]

model_path = None
for path in model_paths:
    if os.path.exists(path):
        model_path = path
        break

if model_path:
    print(f"âœ… ä½¿ç”¨æ¨¡å‹: {model_path}")
    model = YOLO(model_path)
else:
    print("âš ï¸ æ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹...")
    model = YOLO("yolov8n.pt")

# æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰“å¼€æ‘„åƒå¤´
print("ğŸ“· å°è¯•æ‰“å¼€æ‘„åƒå¤´...")
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼å°è¯•åŠ è½½ç¤ºä¾‹å›¾ç‰‡...")
    
    # ä»VOCæ•°æ®é›†åŠ è½½ä¸€äº›å›¾ç‰‡è¿›è¡Œæµ‹è¯•
    test_images = []
    voc_images_dir = "VOCdata/VOC2007/JPEGImages"
    if os.path.exists(voc_images_dir):
        for i, file_name in enumerate(sorted(os.listdir(voc_images_dir))):
            if file_name.lower().endswith(('.jpg', '.jpeg', '.png')) and i < 5:  # åªåŠ è½½5å¼ å›¾ç‰‡
                test_images.append(os.path.join(voc_images_dir, file_name))
    
    if test_images:
        print(f"ğŸ–¼ï¸ åŠ è½½äº† {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡")
        for i, img_path in enumerate(test_images):
            print(f"å¤„ç†å›¾ç‰‡ {i+1}/{len(test_images)}: {img_path}")
            img = cv2.imread(img_path)
            
            # æ£€æµ‹
            start_time = time.time()
            results = model(img)
            elapsed = (time.time() - start_time) * 1000  # æ¯«ç§’
            
            # ç»˜åˆ¶ç»“æœ
            annotated_img = results[0].plot()
            
            # ä¿å­˜ç»“æœ
            save_path = f"detection_result_{i+1}.jpg"
            cv2.imwrite(save_path, annotated_img)
            print(f"âœ… ç»“æœå·²ä¿å­˜: {save_path} (å¤„ç†æ—¶é—´: {elapsed:.1f}ms)")
            
            # å°è¯•æ˜¾ç¤ºç»“æœ
            try:
                cv2.imshow(f"æ£€æµ‹ç»“æœ {i+1}", annotated_img)
                cv2.waitKey(2000)  # æ˜¾ç¤º2ç§’
            except:
                print("âš ï¸ æ— æ³•æ˜¾ç¤ºå›¾åƒï¼Œä»…ä¿å­˜ç»“æœ")
        
        cv2.destroyAllWindows()
    else:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•ç¤ºä¾‹å›¾ç‰‡")
    exit()

print("ğŸ‰ æ‘„åƒå¤´å·²å‡†å¤‡å°±ç»ª! æŒ‰'q'é€€å‡º")

while True:
    ret, frame = cap.read()
    if not ret:
        print("âŒ æ— æ³•è·å–å›¾åƒ!")
        break
    
    # æ£€æµ‹å¯¹è±¡
    results = model(frame)
    
    # ç»˜åˆ¶ç»“æœ
    annotated_frame = results[0].plot()
    
    # æ˜¾ç¤ºç»“æœ
    cv2.imshow("YOLOv8 VOCæ£€æµ‹", annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
print("ğŸ‘‹ ç¨‹åºå·²ç»“æŸ!")
